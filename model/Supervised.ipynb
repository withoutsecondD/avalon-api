{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, MinMaxScaler, RobustScaler,\n",
    "    OneHotEncoder, LabelEncoder, OrdinalEncoder,\n",
    "    PolynomialFeatures\n",
    ")\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparing and preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d10317108d9a92c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/Global_Development_Indicators_2000_2020.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ef0a750652e44ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.fillna(df.mean(numeric_only=True), inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78ef3839a0e3d3f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df.isna().sum())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42658e7979e6d444"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(columns=['region', 'income_group', 'currency_unit'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3006d0561201aef3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df.isna().sum())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c965a470bf81f3d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleared = df.drop(columns=['years_since_2000', 'years_since_century', 'is_pandemic_period', 'human_development_composite', 'year', 'country_code', 'country_name', 'governance_quality_index', 'internet_usage_pct', 'mobile_subscriptions_per_100', 'education_health_ratio', 'global_development_resilience_index', 'co2_intensity_per_million_gdp'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fbb4549453b07f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleared.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c6be3429911fc3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_reg = df_cleared.loc[:, df_cleared.columns != 'inflation_rate']\n",
    "y_reg = df_cleared.loc[:, ['inflation_rate']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d491bc936f59ba1c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_linreg, X_test_linreg, y_train_linreg, y_test_linreg = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "590e8b4d6d03ac54"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multicolinearity check"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3692492aff8fc4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "constant_features = [col for col in X_reg.columns if X_reg[col].nunique() == 1]\n",
    "print(\"Constant features:\", constant_features)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bd8684d17ab6429"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "X_reg_check = X_reg\n",
    "\n",
    "vif_df = pd.DataFrame()\n",
    "vif_df[\"feature\"] = X_reg_check.columns\n",
    "vif_df[\"VIF\"] = [variance_inflation_factor(X_reg_check.values, i) for i in range(X_reg_check.shape[1])]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2d784a9d968b9d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vif_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c37048e592c933e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multicolineared_columns = ['internet_usage_pct', 'mobile_subscriptions_per_100', 'education_health_ratio', 'global_development_resilience_index', 'co2_intensity_per_million_gdp']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cd803257dd15984"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Linear Regresion"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2b3456fb774e818"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_linreg = sm.OLS(y_train_linreg, X_train_linreg).fit()\n",
    "print(model_linreg.summary())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1725b040553f0bf9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds_new = model_linreg.predict(X_test_linreg)\n",
    "print(preds_new)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58aaa54f2c926c59"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r2 = model_linreg.rsquared\n",
    "print('R^2:', r2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d0422fa350c4970"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4de80decab5b4d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mae_linreg = mean_absolute_error(y_test_linreg, preds_new)\n",
    "mse_linreg = mean_squared_error(y_test_linreg, preds_new)\n",
    "rmse_linreg = mean_squared_error(y_test_linreg, preds_new)\n",
    "r2_linreg = r2_score(y_test_linreg, preds_new)\n",
    "\n",
    "print(f'RMSE: {rmse_linreg}')\n",
    "print(f'R^2: {r2_linreg}')\n",
    "print(f'MAE: {mae_linreg}')\n",
    "print(f'MSE: {mse_linreg}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f988d6283e3ec27e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3089aa53e5950097"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleared_class = df.drop(columns=['years_since_2000', 'years_since_century', 'human_development_composite', 'year', 'country_code', 'country_name', 'governance_quality_index', 'internet_usage_pct', 'mobile_subscriptions_per_100', 'education_health_ratio', 'global_development_resilience_index', 'co2_intensity_per_million_gdp'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f41fb8b1c4615c2c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## After analyzing the VIF df with statistical variance decomposing we understood that features:\n",
    "* 'governance_quality_index' \n",
    "* 'internet_usage_pct' \n",
    "* 'mobile_subscriptions_per_100'\n",
    "* 'education_health_ratio'\n",
    "* 'global_development_resilience_index'\n",
    "* 'co2_intensity_per_million_gdp' \n",
    "## Not really insightful to our model and without them we can reduce the effort of model training, remembering the distribution of featurs, and better performance on training time."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27697b253455fb60"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_class = df_cleared_class.loc[:, df_cleared_class.columns != 'is_pandemic_period']\n",
    "y_class = df_cleared_class.loc[:, ['is_pandemic_period']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d7b6083471f7b0d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_class = np.ravel(y_class)\n",
    "y_reg = np.ravel(y_reg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7e85539d848f1cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_logreg, X_test_logreg, y_train_logreg, y_test_logreg = train_test_split(X_class, y_class, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb00d51e145bc0a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5edc8cce5a9adfb2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic regression with LBFGS, L2 regulirization, tolerance 0.001, Regularization factor - 1/C = 0.05 \n",
    "\n",
    "\\begin{aligned}\n",
    "& \\text{Input: Initial guess } w_0, \\text{ parameters } m \\\\\n",
    "& \\text{Initialize: } H_0 = I \\text{ (identity matrix)}, s_0 = \\text{undefined}, y_0 = \\text{undefined} \\\\\n",
    "& \\text{For } k = 1, 2, \\dots \\text{ until convergence:} \\\\\n",
    "& \\quad 1. \\text{Compute the gradient: } g_k = \\nabla f(w_{k-1}) \\\\\n",
    "& \\quad 2. \\text{Compute the search direction: } p_k = -H_{k-1} g_k \\\\\n",
    "& \\quad 3. \\text{Perform a line search to find a step size } \\alpha_k > 0 \\text{ such that } f(w_{k-1} + \\alpha_k p_k) \\text{ is sufficiently decreased.} \\\\\n",
    "& \\quad 4. \\text{Update the parameters: } w_k = w_{k-1} + \\alpha_k p_k \\\\\n",
    "& \\quad 5. \\text{Compute } s_{k-1} = w_k - w_{k-1} = \\alpha_k p_k \\\\\n",
    "& \\quad 6. \\text{Compute } y_{k-1} = g_k - g_{k-1} \\\\\n",
    "& \\quad 7. \\text{Update the inverse Hessian approximation } H_k \\text{ using the L-BFGS update rule based on } (s_{k-1}, y_{k-1}) \\text{ and potentially the } m \\text{ most recent pairs.} \\\\\n",
    "& \\quad \\quad \\text{The two-loop recursion for updating } H_k \\text{ efficiently is often used here.} \\\\\n",
    "& \\text{Output: } w_k \\text{ (the approximate minimizer)}\n",
    "\\end{aligned}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a94540dd6850010c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_logit = LogisticRegression(penalty='l2', tol=1e-4, C=20, solver='lbfgs')\n",
    "model_logit.fit(X_train_logreg, y_train_logreg)\n",
    "\n",
    "probs_logit = model_logit.predict_proba(X_test_logreg)[:, 1]\n",
    "preds_logit = model_logit.predict(X_test_logreg)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test_logreg, preds_logit))\n",
    "print('ROC AUC:', roc_auc_score(y_test_logreg, probs_logit))\n",
    "print('Log Loss:', log_loss(y_test_logreg, probs_logit))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd77e15d6c5c1321"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic regression with saga, elasticnet, tolerance 0.01, Regularization factor - 1/C = 0.05, l1_ration=0.7\n",
    "Apparently in those kind of economical and high numerical dimension what really matters it is solver, how actually the gradient in built, is it counting all numerical features, or trying avoid some. We can actually see that Saga performing better than LBFGS, because of stochastic nature of SAGA and elasticnet regulirization factor. Moreover, SAGA saving information of previous step gradients, it is giving better performance of gradient how to understand the distribution and loss function antology. \n",
    "$$\n",
    "\\min_{w} \\left[ f(w) = \\frac{1}{n} \\sum_{i=1}^{n} f_i(w) + \\lambda R(w) \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "w^{k+1} = w^k - \\eta \\left( \\nabla f_j(w^k) - \\alpha_j + \\frac{1}{n} \\sum_{i=1}^n \\alpha_i + \\lambda \\nabla R(w^k) \\right)\n",
    "$$\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecbcee6b25fbdfe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_logit = LogisticRegression(penalty='elasticnet', tol=1e-3, C=100, solver='saga', l1_ratio=0.7)\n",
    "model_logit.fit(X_train_logreg, y_train_logreg)\n",
    "\n",
    "probs = model_logit.predict_proba(X_test_logreg)[:, 1]\n",
    "preds = model_logit.predict(X_test_logreg)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test_logreg, preds))\n",
    "print('ROC AUC:', roc_auc_score(y_test_logreg, probs))\n",
    "print('Log Loss:', log_loss(y_test_logreg, probs))\n",
    "\n",
    "acc_logit = accuracy_score(y_test_logreg, preds)\n",
    "roc_auc_score_logit = roc_auc_score(y_test_logreg, probs)\n",
    "log_loss_logit = log_loss(y_test_logreg, probs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbfba48496e6c852"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decision Tree Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "883820329bc220d4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, r2_score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a5b01f12e516548"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X_class, y_class, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train_tree_clf = X_train_clf\n",
    "y_train_tree_clf = np.ravel(y_train_clf)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores_decisionTree_clf = []\n",
    "\n",
    "max_depth_range = range(1, 26)\n",
    "\n",
    "for i in max_depth_range:\n",
    "    tree_clf = DecisionTreeClassifier(max_depth=i, random_state=42, criterion='entropy')\n",
    "    scores = cross_val_score(tree_clf, X_train_tree_clf, y_train_tree_clf, cv=5, scoring='f1')\n",
    "    cv_scores_decisionTree_clf.append(scores.mean())\n",
    "    i+=5\n",
    "\n",
    "best_maxdepth_tree_clf = max_depth_range[np.argmax(cv_scores_decisionTree_clf)]\n",
    "print(f'Best k: {best_maxdepth_tree_clf} with f1 score: {max(cv_scores_decisionTree_clf):.4f}')\n",
    "\n",
    "plt.plot(max_depth_range, cv_scores_decisionTree_clf, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('CV f1_score')\n",
    "plt.title('Decision Tree Classifier Cross-Validation f1_score')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b06fa184afdc86f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_f1_score_tree_clf = max(cv_scores_decisionTree_clf)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "645f0061e6427927"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decision Tree Regressor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f52bcfd4929fd9be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_tree_reg = X_train_linreg\n",
    "y_train_tree_reg = np.ravel(y_train_linreg)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores_decisionTree_reg = []\n",
    "\n",
    "max_depth_range = range(1, 26)\n",
    "\n",
    "for i in max_depth_range:\n",
    "    tree_reg = DecisionTreeRegressor(max_depth=i, random_state=42, criterion='absolute_error')\n",
    "    scores = cross_val_score(tree_reg, X_train_tree_reg, y_train_tree_reg, cv=5, scoring='d2_absolute_error_score')\n",
    "    cv_scores_decisionTree_reg.append(scores.mean())\n",
    "    i+=5\n",
    "\n",
    "best_maxdepth_tree_reg = max_depth_range[np.argmax(cv_scores_decisionTree_reg)]\n",
    "print(f'Best k: {best_maxdepth_tree_reg} with d2_absolute_error score: {max(cv_scores_decisionTree_reg):.4f}')\n",
    "\n",
    "plt.plot(max_depth_range, cv_scores_decisionTree_reg, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('CV absolute_error')\n",
    "plt.title('Decision Tree Regressor Cross-Validation absolute error')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a578c7855b07622e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_d2_mae_dtree_reg = max(cv_scores_decisionTree_reg)\n",
    "print(best_d2_mae_dtree_reg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3aa7243da7f7f640"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43189b7c3a771cbf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "y_train_clf = np.ravel(y_train_clf)\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42, criterion='entropy')\n",
    "forest_clf.fit(X_train_clf, y_train_clf)\n",
    "y_pred_forest_clf = forest_clf.predict(X_test_clf)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test_clf, y_pred_forest_clf) )\n",
    "\n",
    "acc_forest_clf = accuracy_score(y_test_clf, y_pred_forest_clf)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a86c9417bee00047"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train_tree_reg = np.ravel(y_train_tree_reg)\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=5, max_depth=5, random_state=42, criterion='absolute_error')\n",
    "reg.fit(X_train_tree_reg, y_train_tree_reg)\n",
    "y_pred_forest_reg = reg.predict(X_test_linreg)\n",
    "\n",
    "print('MAE:', mean_absolute_error(y_test_linreg, y_pred_forest_reg))\n",
    "\n",
    "mae_random_reg = mean_absolute_error(y_test_linreg, y_pred_forest_reg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28cca250c4663783"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Naive Bayess Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6adfda88c7e2a3dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_NB = X_class\n",
    "y_NB = np.ravel(y_class)\n",
    "\n",
    "X_train_NB, X_test_NB, y_train_NB, y_test_NB = train_test_split(X_NB, y_NB, random_state=42, test_size=0.3)\n",
    "\n",
    "\n",
    "NB = GaussianNB()\n",
    "NB.fit(X_train_NB, y_train_NB)\n",
    "y_pred_NB = NB.predict(X_test_NB)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test_NB, y_pred_NB))\n",
    "\n",
    "acc_nb = accuracy_score(y_test_NB, y_pred_NB)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8297aafb2f9d4105"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results of Naive Bayes Classifier showing that still the dataset having really good composition and distribution, extremely predictable, cleared from colinearity, having thorough feature clearing, and numerical nature. Nevertheless, we can assume that this high numerical dependence giving such a low sensivity for events and probability distribution for this type of dataset. During the whole analysis we can mark up that high level of numerical nature of dataset giving outstanding results for region classifying and regression, but in a case of probability classifying it gives gradually lower results of Accuracy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75a3fb56c37feb71"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# kNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2b304319e8ba359"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "k_range = [i for i in range(1, 22) if i % 2 != 0]\n",
    "cv_scores_knn_clf = []\n",
    "\n",
    "X_knn_clf = X_class\n",
    "y_knn_clf = np.ravel(y_class)\n",
    "\n",
    "\n",
    "for k in k_range:\n",
    "    kNN_clf = KNeighborsClassifier(n_neighbors=k, metric='manhattan')\n",
    "    scores = cross_val_score(kNN_clf, X_knn_clf, y_knn_clf, cv=5, scoring='accuracy')\n",
    "    cv_scores_knn_clf.append(scores.mean())\n",
    "\n",
    "best_k_clf = k_range[np.argmax(cv_scores_knn_clf)]\n",
    "print(f'Best k: {best_k_clf} with accuracy: {max(cv_scores_knn_clf):.4f}')\n",
    "\n",
    "plt.plot(k_range, cv_scores_knn_clf, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('CV Accuracy')\n",
    "plt.title('kNN_clf Cross-Validation Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(cv_scores_knn_clf)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aeb138d7f9e53876"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_acc_knn_clf = max(cv_scores_knn_clf)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38453bc6cb0319fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k_range = [i for i in range(1, 22) if i%2!=0]\n",
    "cv_scores_knn_reg = []\n",
    "\n",
    "X_knn_reg = X_reg\n",
    "y_knn_reg = y_reg\n",
    "\n",
    "\n",
    "for k in k_range:\n",
    "    kNN_reg = KNeighborsRegressor(n_neighbors=k, metric='minkowski')\n",
    "    scores = cross_val_score(kNN_reg, X_knn_reg, y_knn_reg, cv=5, scoring='neg_mean_absolute_error')\n",
    "    cv_scores_knn_reg.append(scores.mean())\n",
    "\n",
    "best_k_reg = k_range[np.argmax(cv_scores_knn_reg)]\n",
    "best_neg_mae_knn_reg = max(cv_scores_knn_reg)\n",
    "best_mae_knnreg = -best_neg_mae_knn_reg \n",
    "\n",
    "print(f'Best k (based on MAE): {best_k_reg} with MAE: {best_mae_knnreg:.4f}')\n",
    "\n",
    "plt.plot(k_range, [-score for score in cv_scores_knn_reg], marker='o') # Plot the actual MAE values\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('CV MAE')\n",
    "plt.title('kNN_reg Cross-Validation MAE')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "cv_scores_knn_reg_cleared = [-score for score in cv_scores_knn_reg]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79047d995be5ac4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVC"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1c80845ccd48662"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "X_svc = X_class\n",
    "y_svc = np.ravel(y_class)\n",
    "\n",
    "X_train_svc, X_test_svc, y_train_svc, y_test_svc = train_test_split(X_svc, y_svc, test_size=0.3, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(SVC(class_weight='balanced'), param_grid, cv=5)\n",
    "grid.fit(X_train_svc, y_train_svc)\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "best_model.fit(X_train_svc, y_train_svc)\n",
    "y_preds_svc = best_model.predict(X_test_svc)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_preds_svc, y_test_svc))\n",
    "print('F1 score:', f1_score(y_preds_svc, y_test_svc))\n",
    "\n",
    "acc_svc = accuracy_score(y_preds_svc, y_test_svc)\n",
    "f1_svc = f1_score(y_preds_svc, y_test_svc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7775932d341db76b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overall we can see that actually making predictions and trying to model the pandemic period it is actually wrong from the view of statistical distribution, because model not trying to predict the pandemic period, it is just choosing certain region where exactly it should be with certain economical, social and political features. Definitely, model not relying on year, country, or others. It is just a modeling of economical features which could marking up the situation of pandemic crisis. Nevertheless, it is better not to model the region of features where you having same class. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16f03d7b5a59862b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Simple documentation for different metrics variables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da8e591a6d2ecffd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ===== Regression ===== #\n",
    "# Linear regression \n",
    "## mae_linreg\n",
    "## mse_linreg\n",
    "## rmse_linreg\n",
    "## r2_linreg\n",
    "\n",
    "# Decision tree regressor\n",
    "## best_maxdepth_tree_reg\n",
    "## best_d2_mae_dtree_reg\n",
    "## cv_scores_decisionTree_reg\n",
    "\n",
    "# Random forest regressor\n",
    "## mae_random_reg\n",
    "\n",
    "# kNN regressor\n",
    "## cv_scores_knn_reg_cleared\n",
    "## best_k_reg\n",
    "## best_mae_knnreg\n",
    "\n",
    "# ===== Classification ===== #\n",
    "# Logistic regression\n",
    "## acc_logit\n",
    "## roc_auc_score_logit\n",
    "## log_loss_logit\n",
    "\n",
    "# Decision tree classifier\n",
    "## best_f1_score_tree_clf\n",
    "## best_maxdepth_tree_clf\n",
    "## cv_scores_decisionTree_clf\n",
    "\n",
    "# Random forest classifier\n",
    "## acc_forest_clf\n",
    "\n",
    "# Naive Bayes classifier\n",
    "## acc_nb\n",
    "\n",
    "# kNN classifier\n",
    "## best_acc_knn_clf\n",
    "## cv_scores_knn_clf\n",
    "## best_k_clf\n",
    "\n",
    "# SVC\n",
    "## acc_svc\n",
    "## f1_svc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f41a7c44de8d7a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing the variables of metrics into Supervised.json file for our ML infrastructure"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a3a084528fce198"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def export_model_results(\n",
    "        # Регрессия — linear\n",
    "        linear_r2, linear_rmse, linear_mae, linear_mse,\n",
    "\n",
    "        # Регрессия — dtree\n",
    "        dtree_d2mae, dtree_cv_d2mae, dtree_best_maxdepth,\n",
    "\n",
    "        # Регрессия — random forest\n",
    "        rf_reg_mae,\n",
    "\n",
    "        # Регрессия — knn\n",
    "        knn_reg_mae, knn_reg_cv_mae, knn_reg_best_k,\n",
    "\n",
    "        # Классификация — logistic\n",
    "        log_accuracy, log_roc_auc, log_loss,\n",
    "\n",
    "        # Классификация — dtree\n",
    "        dtree_clf_f1, dtree_clf_cv_f1, dtree_clf_best_maxdepth,\n",
    "\n",
    "        # Классификация — random forest\n",
    "        rf_clf_accuracy,\n",
    "\n",
    "        # Классификация — naive Bayes\n",
    "        naiveb_accuracy,\n",
    "\n",
    "        # Классификация — knn\n",
    "        knn_clf_accuracy, knn_clf_cv_accuracy, knn_clf_best_k,\n",
    "\n",
    "        # Классификация — SVC\n",
    "        svc_accuracy, svc_f1,\n",
    "\n",
    "        # Имя файла (по умолчанию)\n",
    "        filename=\"supervised.json\"\n",
    "):\n",
    "    results = {\n",
    "        \"regression\": {\n",
    "            \"linear\": {\n",
    "                \"r2\": linear_r2,\n",
    "                \"rmse\": linear_rmse,\n",
    "                \"mae\": linear_mae,\n",
    "                \"mse\": linear_mse\n",
    "            },\n",
    "            \"dtree_reg\": {\n",
    "                \"d2mae\": dtree_d2mae,\n",
    "                \"cv_results\": {\n",
    "                    \"d2mae_results\": dtree_cv_d2mae,\n",
    "                    \"best_maxdepth\": dtree_best_maxdepth\n",
    "                }\n",
    "            },\n",
    "            \"randomforest_reg\": {\n",
    "                \"mae\": rf_reg_mae\n",
    "            },\n",
    "            \"knn\": {\n",
    "                \"mae\": knn_reg_mae,\n",
    "                \"cv_results\": {\n",
    "                    \"mae_results\": knn_reg_cv_mae,\n",
    "                    \"best_k\": knn_reg_best_k\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"classification\": {\n",
    "            \"logistic\": {\n",
    "                \"accuracy\": log_accuracy,\n",
    "                \"roc_auc\": log_roc_auc,\n",
    "                \"log_loss\": log_loss\n",
    "            },\n",
    "            \"dtree_clf\": {\n",
    "                \"accuracy\": dtree_clf_f1,\n",
    "                \"cv_results\": {\n",
    "                    \"accuracy_results\": dtree_clf_cv_f1,\n",
    "                    \"best_maxdepth\": dtree_clf_best_maxdepth\n",
    "                }\n",
    "            },\n",
    "            \"randomforest_clf\": {\n",
    "                \"accuracy\": rf_clf_accuracy\n",
    "            },\n",
    "            \"naiveB\": {\n",
    "                \"accuracy\": naiveb_accuracy\n",
    "            },\n",
    "            \"knn\": {\n",
    "                \"accuracy\": knn_clf_accuracy,\n",
    "                \"cv_results\": {\n",
    "                    \"accuracy_results\": knn_clf_cv_accuracy,\n",
    "                    \"best_k\": knn_clf_best_k\n",
    "                }\n",
    "            },\n",
    "            \"svc\": {\n",
    "                \"accuracy\": svc_accuracy,\n",
    "                \"f1_score\": svc_f1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    print(f\"[INFO] Results exported to {filename}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bd7af1d04e25092"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "export_model_results(\n",
    "    linear_r2=r2_linreg, linear_rmse=rmse_linreg, linear_mae=mae_linreg, linear_mse=mse_linreg,\n",
    "\n",
    "    dtree_d2mae=best_d2_mae_dtree_reg, dtree_cv_d2mae=cv_scores_decisionTree_reg, dtree_best_maxdepth=best_maxdepth_tree_reg,\n",
    "\n",
    "    rf_reg_mae=mae_random_reg,\n",
    "\n",
    "    knn_reg_mae=best_mae_knnreg, knn_reg_cv_mae=cv_scores_knn_reg_cleared, knn_reg_best_k=best_k_reg,\n",
    "\n",
    "    log_accuracy=acc_logit, log_roc_auc=roc_auc_score_logit, log_loss=log_loss_logit,\n",
    "\n",
    "    dtree_clf_f1=best_f1_score_tree_clf, dtree_clf_cv_f1=cv_scores_decisionTree_clf, dtree_clf_best_maxdepth=best_maxdepth_tree_clf,\n",
    "\n",
    "    rf_clf_accuracy=acc_forest_clf,\n",
    "\n",
    "    naiveb_accuracy=acc_nb,\n",
    "\n",
    "    knn_clf_accuracy=best_acc_knn_clf, knn_clf_cv_accuracy=cv_scores_knn_clf, knn_clf_best_k=best_k_clf,\n",
    "\n",
    "    svc_accuracy=acc_svc, svc_f1=f1_svc,\n",
    "\n",
    "    filename=\"results/supervised.json\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f432f1ed51a672f3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving preprocessed data and VIF table"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6a72f3740ea1234"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_csv(df_to_save, name):\n",
    "    df_to_save.to_csv(f\"../resources/{name}.csv\", index=False)\n",
    "    print(f\"[INFO] DataFrame сохранён в resources/{name}.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d3057271de71d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_csv(df_cleared_class, \"preprocessed\")\n",
    "save_csv(vif_df, 'vif')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a0ebafded7fa50c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
